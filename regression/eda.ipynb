{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-06T16:23:02.347446Z",
     "end_time": "2023-05-06T16:23:25.246181Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_188102/4215461173.py:5: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  social = pd.read_csv(\"Aggregated_reddit_twitter.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "social = pd.read_csv(\"Aggregated_reddit_twitter.csv\")\n",
    "social = social.rename(columns={\"date\": \"timestamp\"})\n",
    "social[\"timestamp\"] = pd.to_datetime(social[\"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "social = social[social.content != \"u/circular360\"]\n",
    "social = social[social.content != \"There you go\"]\n",
    "social = social[\n",
    "    social.content != \"Why force the other player to stay around? Just give the winning player the option to continue the game with a perma passing AI controlling the surrendering player.\"]\n",
    "# crypto = pd.read_csv(\"transformed_crypto.csv\")\n",
    "# crypto[\"timestamp\"] = pd.to_datetime(crypto[\"timestamp\"]).dt.tz_localize(None)\n",
    "crypto = pd.read_csv(\"crypto_differences.csv\")\n",
    "crypto[\"timestamp\"] = pd.to_datetime(crypto[\"timestamp\"]).dt.tz_localize(None)\n",
    "\n",
    "social = social.sort_values(by=\"timestamp\")\n",
    "# social.dtypes\n",
    "sr = social.resample(\"T\", on=\"timestamp\").size()\n",
    "freq = sr.reset_index()\n",
    "\n",
    "freq = freq.rename(columns={0: \"n_comments\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T16:23:25.240081Z",
     "end_time": "2023-05-06T16:23:42.760467Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                  timestamp  n_comments  hour  day  month\n0       2021-03-01 00:00:00          18     0    0      3\n1       2021-03-01 00:01:00           8     0    0      3\n2       2021-03-01 00:02:00           4     0    0      3\n3       2021-03-01 00:03:00          11     0    0      3\n4       2021-03-01 00:04:00           4     0    0      3\n...                     ...         ...   ...  ...    ...\n1132079 2023-04-26 03:59:00           0     3    2      4\n1132080 2023-04-26 04:00:00           0     4    2      4\n1132081 2023-04-26 04:01:00           0     4    2      4\n1132082 2023-04-26 04:02:00           0     4    2      4\n1132083 2023-04-26 04:03:00           1     4    2      4\n\n[1132084 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>n_comments</th>\n      <th>hour</th>\n      <th>day</th>\n      <th>month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-03-01 00:00:00</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-03-01 00:01:00</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-03-01 00:02:00</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-03-01 00:03:00</td>\n      <td>11</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-03-01 00:04:00</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1132079</th>\n      <td>2023-04-26 03:59:00</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1132080</th>\n      <td>2023-04-26 04:00:00</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1132081</th>\n      <td>2023-04-26 04:01:00</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1132082</th>\n      <td>2023-04-26 04:02:00</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1132083</th>\n      <td>2023-04-26 04:03:00</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>1132084 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq[\"hour\"] = freq[\"timestamp\"].dt.hour\n",
    "freq[\"day\"] = freq[\"timestamp\"].dt.dayofweek\n",
    "freq[\"month\"] = freq[\"timestamp\"].dt.month\n",
    "freq"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T16:23:42.752676Z",
     "end_time": "2023-05-06T16:23:42.847112Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# freq.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T16:23:42.843041Z",
     "end_time": "2023-05-06T16:23:42.847272Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "mg = pd.merge(crypto, freq, on=\"timestamp\", how=\"inner\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T16:23:42.845045Z",
     "end_time": "2023-05-06T16:23:43.361130Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T16:23:43.351785Z",
     "end_time": "2023-05-06T16:23:43.361438Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "       Unnamed: 0  XRP-PERP  SOL-PERP  ETH-PERP  DOGE-PERP  BTC-PERP   \n0           84948 -0.004460 -0.000038 -0.003975  -0.001777  0.019043  \\\n1           84949 -0.002579 -0.000615 -0.000643   0.000318  0.034964   \n2           84950 -0.002167 -0.001020 -0.005845  -0.001372  0.017780   \n3           84951  0.009470 -0.000019  0.003271   0.000811 -0.006938   \n4           84952  0.001695  0.000981  0.001503  -0.000601 -0.047523   \n...           ...       ...       ...       ...        ...       ...   \n19996      104946  0.001507  0.000059  0.001462  -0.000024 -0.003089   \n19997      104947  0.000669  0.000059  0.001738   0.001781 -0.001874   \n19998      104948  0.003797  0.000355  0.000694  -0.000374 -0.002395   \n19999      104949 -0.003797 -0.000118 -0.001806  -0.000099  0.002803   \n20000      104950  0.001295  0.000039 -0.001531  -0.000348  0.000706   \n\n                timestamp  n_comments  hour  day  month  \n0     2021-03-01 00:00:00          18     0    0      3  \n1     2021-03-01 00:01:00           8     0    0      3  \n2     2021-03-01 00:02:00           4     0    0      3  \n3     2021-03-01 00:03:00          11     0    0      3  \n4     2021-03-01 00:04:00           4     0    0      3  \n...                   ...         ...   ...  ...    ...  \n19996 2021-03-14 21:26:00          46    21    6      3  \n19997 2021-03-14 21:27:00          40    21    6      3  \n19998 2021-03-14 21:28:00          46    21    6      3  \n19999 2021-03-14 21:29:00          42    21    6      3  \n20000 2021-03-14 21:30:00          44    21    6      3  \n\n[20001 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>XRP-PERP</th>\n      <th>SOL-PERP</th>\n      <th>ETH-PERP</th>\n      <th>DOGE-PERP</th>\n      <th>BTC-PERP</th>\n      <th>timestamp</th>\n      <th>n_comments</th>\n      <th>hour</th>\n      <th>day</th>\n      <th>month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>84948</td>\n      <td>-0.004460</td>\n      <td>-0.000038</td>\n      <td>-0.003975</td>\n      <td>-0.001777</td>\n      <td>0.019043</td>\n      <td>2021-03-01 00:00:00</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>84949</td>\n      <td>-0.002579</td>\n      <td>-0.000615</td>\n      <td>-0.000643</td>\n      <td>0.000318</td>\n      <td>0.034964</td>\n      <td>2021-03-01 00:01:00</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84950</td>\n      <td>-0.002167</td>\n      <td>-0.001020</td>\n      <td>-0.005845</td>\n      <td>-0.001372</td>\n      <td>0.017780</td>\n      <td>2021-03-01 00:02:00</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84951</td>\n      <td>0.009470</td>\n      <td>-0.000019</td>\n      <td>0.003271</td>\n      <td>0.000811</td>\n      <td>-0.006938</td>\n      <td>2021-03-01 00:03:00</td>\n      <td>11</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84952</td>\n      <td>0.001695</td>\n      <td>0.000981</td>\n      <td>0.001503</td>\n      <td>-0.000601</td>\n      <td>-0.047523</td>\n      <td>2021-03-01 00:04:00</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19996</th>\n      <td>104946</td>\n      <td>0.001507</td>\n      <td>0.000059</td>\n      <td>0.001462</td>\n      <td>-0.000024</td>\n      <td>-0.003089</td>\n      <td>2021-03-14 21:26:00</td>\n      <td>46</td>\n      <td>21</td>\n      <td>6</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>19997</th>\n      <td>104947</td>\n      <td>0.000669</td>\n      <td>0.000059</td>\n      <td>0.001738</td>\n      <td>0.001781</td>\n      <td>-0.001874</td>\n      <td>2021-03-14 21:27:00</td>\n      <td>40</td>\n      <td>21</td>\n      <td>6</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>19998</th>\n      <td>104948</td>\n      <td>0.003797</td>\n      <td>0.000355</td>\n      <td>0.000694</td>\n      <td>-0.000374</td>\n      <td>-0.002395</td>\n      <td>2021-03-14 21:28:00</td>\n      <td>46</td>\n      <td>21</td>\n      <td>6</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>19999</th>\n      <td>104949</td>\n      <td>-0.003797</td>\n      <td>-0.000118</td>\n      <td>-0.001806</td>\n      <td>-0.000099</td>\n      <td>0.002803</td>\n      <td>2021-03-14 21:29:00</td>\n      <td>42</td>\n      <td>21</td>\n      <td>6</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>20000</th>\n      <td>104950</td>\n      <td>0.001295</td>\n      <td>0.000039</td>\n      <td>-0.001531</td>\n      <td>-0.000348</td>\n      <td>0.000706</td>\n      <td>2021-03-14 21:30:00</td>\n      <td>44</td>\n      <td>21</td>\n      <td>6</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>20001 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortmg = mg.loc[0:20000]\n",
    "shortmg.dropna()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T16:23:43.354656Z",
     "end_time": "2023-05-06T16:23:43.368055Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "class MyTimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data.loc[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "# data = MyTimeSeriesDataset(X_data=shortmg[['n_comments', 'XRP-PERP', 'ETH-PERP']], y_data=shortmg['BTC-PERP'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T16:23:43.369654Z",
     "end_time": "2023-05-06T16:23:43.371669Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 2, 1, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset into a pandas DataFrame called 'data'\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Scale the features using MinMaxScaler\n",
    "cs = ['BTC-PERP', 'XRP-PERP', 'ETH-PERP', 'SOL-PERP', 'DOGE-PERP']\n",
    "scaled_data = shortmg[cs + [\"hour\", \"day\", \"month\", \"n_comments\"]]\n",
    "# scaled_data = shortmg[['XRP-PERP', 'ETH-PERP', 'BTC-PERP', 'SOL-PERP', 'DOGE-PERP', 'n_comments']].to_numpy()\n",
    "\n",
    "# scaled_data = abs(scaled_data)\n",
    "\n",
    "\n",
    "# scaled_data = scaled_data.to_numpy()\n",
    "#\n",
    "scaler = StandardScaler()\n",
    "#\n",
    "scaled_data = scaled_data.to_numpy()\n",
    "# scaled_data = scaler.fit_transform(scaled_data)\n",
    "\n",
    "\n",
    "# Create sequences and targets for the RNN model\n",
    "seq_length = 60\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "future = 5\n",
    "\n",
    "for i in range(len(scaled_data) - seq_length - future):\n",
    "    X_data.append(scaled_data[i:i + seq_length].flatten())\n",
    "    y_data.append(scaled_data[i + seq_length + future])\n",
    "\n",
    "x_data = scaler.fit_transform(X_data)\n",
    "# y_data = np.delete(y_data, [-1, -2, -3, -4], axis=1)\n",
    "y_data = np.delete(y_data, [-1, -2, -3, -4, -5, -6, -7, -8], axis=1)\n",
    "# to make classifier\n",
    "epsilon = 0.002\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    if x > epsilon:\n",
    "        return 1\n",
    "    elif x < -epsilon:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "[0, 0, 1]\n",
    "[0, 1, 0]\n",
    "[1, 0, 0]\n",
    "y_data = list(map(f, y_data))\n",
    "\n",
    "print(y_data[1:10])\n",
    "X_data, y_data = np.array(X_data), np.array(y_data)\n",
    "\n",
    "y_data = y_data.astype(np.int64)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T16:23:43.375501Z",
     "end_time": "2023-05-06T16:23:44.439917Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "train_size = int(len(X_data) * 0.8)\n",
    "X_train, X_test = X_data[:train_size], X_data[train_size:]\n",
    "y_train, y_test = y_data[:train_size], y_data[train_size:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T16:23:44.427993Z",
     "end_time": "2023-05-06T16:23:44.440206Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.6888305337275618, 0.6369096698707718)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = y_test.mean(axis=0)\n",
    "((y_test - m) ** 2).mean()\n",
    "y_test.var(), y_train.var()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T16:23:44.428034Z",
     "end_time": "2023-05-06T16:23:44.440737Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dario/PycharmProjects/BAINSACryptocurrencies/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# regressor = RandomForestRegressor(random_state=0, max_depth=5, n_estimators=20)\n",
    "# regressor = SVR()\n",
    "regressor = LogisticRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "pred = regressor.predict(X_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T16:23:44.428087Z",
     "end_time": "2023-05-06T16:23:46.889117Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 256\n",
    "train_dataset = TimeSeriesDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).float())\n",
    "test_dataset = TimeSeriesDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).float())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T16:23:46.887877Z",
     "end_time": "2023-05-06T16:23:46.980319Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "(Counter({0: 2049, 2: 983, 1: 956}), Counter({0: 4655, 2: 5553, 1: 5740}))"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier\n",
    "# y_data = y_data.flatten()\n",
    "# y_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T16:30:15.396622Z",
     "end_time": "2023-05-06T16:30:15.400801Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, d_model, nhead, num_layers, output_size):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Linear(input_size, d_model)\n",
    "        self.transformer_encoder_layer = nn.TransformerEncoderLayer(d_model, nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.transformer_encoder_layer, num_layers)\n",
    "        self.fc = nn.Linear(d_model, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.transpose(0, 1)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.transpose(0, 1)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "\n",
    "class DenseModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(input_size, 256)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = torch.flatten(x, 1)\n",
    "        x = self.lin(x)\n",
    "        x = self.ff(x)\n",
    "        o = f.softmax(x, dim=1)\n",
    "        return o"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T16:23:52.085194Z",
     "end_time": "2023-05-06T16:23:52.093473Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "(540, 3)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import optim\n",
    "import torch.nn.functional as f\n",
    "\n",
    "input_size = X_data.shape[1]\n",
    "# hidden_size = 256\n",
    "# num_layers = 8\n",
    "# output_size = y_data.shape[1]\n",
    "output_size = 3\n",
    "# output_size = 1\n",
    "\n",
    "# model = RNNModel(input_size, hidden_size, num_layers, output_size)\n",
    "# model = TransformerModel(input_size, d_model=32, nhead=2, num_layers=2, output_size=output_size)\n",
    "model = DenseModel(input_size, output_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "input_size, output_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T16:29:02.125635Z",
     "end_time": "2023-05-06T16:29:02.171838Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 1.1934, Test Loss: 1.1492, accuracy: 24.648946840521564\n",
      "Epoch: 2, Train Loss: 1.1934, Test Loss: 1.1492, accuracy: 24.648946840521564\n",
      "Epoch: 3, Train Loss: 1.1934, Test Loss: 1.1492, accuracy: 24.648946840521564\n",
      "Epoch: 4, Train Loss: 1.1934, Test Loss: 1.1492, accuracy: 24.648946840521564\n",
      "Epoch: 5, Train Loss: 1.1934, Test Loss: 1.1492, accuracy: 24.648946840521564\n",
      "Epoch: 6, Train Loss: 1.1934, Test Loss: 1.1492, accuracy: 24.648946840521564\n",
      "Epoch: 7, Train Loss: 1.1934, Test Loss: 1.1492, accuracy: 24.648946840521564\n",
      "Epoch: 8, Train Loss: 1.1934, Test Loss: 1.1492, accuracy: 24.648946840521564\n",
      "Epoch: 9, Train Loss: 1.1934, Test Loss: 1.1492, accuracy: 24.648946840521564\n",
      "Epoch: 10, Train Loss: 1.1934, Test Loss: 1.1492, accuracy: 24.648946840521564\n",
      "Epoch: 11, Train Loss: 1.1934, Test Loss: 1.1492, accuracy: 24.648946840521564\n",
      "Epoch: 12, Train Loss: 1.1934, Test Loss: 1.1492, accuracy: 24.648946840521564\n",
      "Epoch: 13, Train Loss: 1.1934, Test Loss: 1.1492, accuracy: 24.648946840521564\n",
      "Epoch: 14, Train Loss: 1.1934, Test Loss: 1.1492, accuracy: 24.648946840521564\n",
      "Epoch: 15, Train Loss: 1.1934, Test Loss: 1.1492, accuracy: 24.648946840521564\n",
      "Epoch: 16, Train Loss: 1.1934, Test Loss: 1.1492, accuracy: 24.648946840521564\n",
      "Epoch: 17, Train Loss: 1.1934, Test Loss: 1.1492, accuracy: 24.648946840521564\n",
      "Epoch: 18, Train Loss: 1.1934, Test Loss: 1.1492, accuracy: 24.648946840521564\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[34], line 22\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# print(loss)\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# print(loss.item())\u001B[39;00m\n\u001B[1;32m     21\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m---> 22\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# optimizer.step()\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_idx \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m20\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m log:\n",
      "File \u001B[0;32m~/PycharmProjects/BAINSACryptocurrencies/venv/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     32\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m---> 33\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     35\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(prev_grad)\n",
      "File \u001B[0;32m~/PycharmProjects/BAINSACryptocurrencies/venv/lib/python3.10/site-packages/torch/optim/adam.py:141\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    130\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    132\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[1;32m    133\u001B[0m         group,\n\u001B[1;32m    134\u001B[0m         params_with_grad,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    138\u001B[0m         max_exp_avg_sqs,\n\u001B[1;32m    139\u001B[0m         state_steps)\n\u001B[0;32m--> 141\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    142\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    143\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    145\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    146\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    148\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/PycharmProjects/BAINSACryptocurrencies/venv/lib/python3.10/site-packages/torch/optim/adam.py:281\u001B[0m, in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    279\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[0;32m--> 281\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    284\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[43m     \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    287\u001B[0m \u001B[43m     \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    288\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    289\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    290\u001B[0m \u001B[43m     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    291\u001B[0m \u001B[43m     \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    292\u001B[0m \u001B[43m     \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    293\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    294\u001B[0m \u001B[43m     \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    295\u001B[0m \u001B[43m     \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    296\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    297\u001B[0m \u001B[43m     \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/BAINSACryptocurrencies/venv/lib/python3.10/site-packages/torch/optim/adam.py:393\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[1;32m    390\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    391\u001B[0m     denom \u001B[38;5;241m=\u001B[39m (exp_avg_sq\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[0;32m--> 393\u001B[0m \u001B[43mparam\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maddcdiv_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexp_avg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdenom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43mstep_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "num_epochs = 30\n",
    "log = False\n",
    "#\n",
    "if \"Linux\" in platform.platform():\n",
    "    model = torch.compile(model)\n",
    "#\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "        y_pred = model(X_batch)\n",
    "        #\n",
    "        optimizer.zero_grad()\n",
    "        y_batch = y_batch.type(torch.LongTensor)\n",
    "        loss = f.nll_loss(y_pred, y_batch)\n",
    "        print(loss)\n",
    "        print(loss.item())\n",
    "        input()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # optimizer.step()\n",
    "\n",
    "        if batch_idx % 20 == 0 and True:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(X_batch), len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n",
    "                loss))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            y_pred = model(X_batch)\n",
    "            y_batch = y_batch.type(torch.LongTensor)\n",
    "\n",
    "            loss = f.nll_loss(y_pred, y_batch)\n",
    "            test_loss += loss\n",
    "\n",
    "        test_loss = test_loss / len(test_loader)\n",
    "\n",
    "        print(f\"Epoch: {epoch + 1}, Train Loss: {loss.item():.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T15:32:37.800225Z",
     "end_time": "2023-05-06T15:33:05.072724Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
